import numpy as np
from scipy.sparse import save_npz, load_npz, csr_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics, svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import ComplementNB

from Utils.Extract_feature import extract_ngrams, extract_bytes_sequence, extract_opcode_sequence, count_asm_opcode, \
    extract_syscall, save_syscall, check_syscall, load_syscall, extract_syscall_sequence
from pathlib import Path
import pandas as pd


data_dir = Path("data")
smp_dir = data_dir.joinpath("samples")
ftr_dir = Path("pre-extract")
if not ftr_dir.exists():
    ftr_dir.mkdir()

if __name__ == '__main__':
    # label_benign_file()
    lbls = pd.read_csv(data_dir.joinpath("trainLabels_malign.csv"))
    lbls["Id"] = lbls["Id"].astype(str)
    lbls["Class"] = lbls["Class"].astype("category")
    lbls.set_index("Id", inplace=True)

    # bytes_ngram_vct, bytes_ngrams = extract_ngrams(lbls.index, extract_bytes_sequence, 3)
    # print(bytes_ngrams.shape)
    #
    # col_sum = bytes_ngrams.sum(axis=0).A1
    # top_frqn_ftr_idx = np.argsort(col_sum)[::-1][:5000]
    # print(col_sum[top_frqn_ftr_idx])
    #
    # save_npz(ftr_dir.joinpath("bytes_3grams.npz"), bytes_ngrams[:, top_frqn_ftr_idx])

    # opcodes_ngram_vct, opcodes_ngrams = extract_ngrams(lbls.index, extract_opcode_sequence, 4)
    # print(opcodes_ngrams.shape)
    #
    # col_sum = opcodes_ngrams.sum(axis=0).A1
    # top_frqn_ftr_idx = np.argsort(col_sum)[::-1][:5000]
    # print(col_sum[top_frqn_ftr_idx])
    #
    # save_npz(ftr_dir.joinpath("opcodes_4grams.npz"), opcodes_ngrams[:, top_frqn_ftr_idx])
    #
    # opcode_counter = []
    #
    # for file in lbls.index:
    #     opc_counter = count_asm_opcode(file)
    #     opcode_counter.append(opc_counter)
    #
    # feature_to_save = np.array(opcode_counter)
    # save_npz(ftr_dir.joinpath("opcode_counters.npz"), csr_matrix(feature_to_save))

    # for file in lbls.index:
    #     extract_syscall(file)
    # save_syscall()
    #
    # syscall_vct = []
    # load_syscall()
    # for file in lbls.index:
    #     syscall_vct.append(check_syscall(file))
    #
    # feature_to_save = np.array(syscall_vct)
    # save_npz(ftr_dir.joinpath("syscall_check.npz"), csr_matrix(feature_to_save))

    api_ngrm_vct, api_ngrms = extract_ngrams(lbls.index, extract_syscall_sequence, 4)
    print(api_ngrms.shape)

    col_sum = api_ngrms.sum(axis=0).A1
    top_frqn_ftr_idx = np.argsort(col_sum)[::-1][:5000]
    print(col_sum[top_frqn_ftr_idx])

    save_npz(ftr_dir.joinpath("api_4grams.npz"), api_ngrms[:, top_frqn_ftr_idx])

    X = pd.DataFrame(load_npz(ftr_dir.joinpath("api_4grams.npz")).toarray()).set_index(lbls.index)
    print(X.head())

    X_train, X_test, y_train, y_test = train_test_split(X, lbls, test_size=0.15, stratify=lbls)

    y_train = y_train.values.ravel()

    clf = RandomForestClassifier()
    clf.fit(X_train, y_train)
    clf_y_pred = clf.predict(X_test)
    print("RF F1 score for each class: ", metrics.f1_score(y_test, clf_y_pred, average=None))
    print("RF F1 score (macro): ", metrics.f1_score(y_test, clf_y_pred, average='weighted'))
    print()
    print("RF Confusion Metrix:\n", metrics.confusion_matrix(y_test, clf_y_pred))

    print("---------------------------")

    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train, y_train)
    knn_y_pred = knn.predict(X_test)
    print("KNN F1 score for each class: ", metrics.f1_score(y_test, knn_y_pred, average=None))
    print("KNN F1 score (macro): ", metrics.f1_score(y_test, knn_y_pred, average='weighted'))
    print()
    print("K-NN Confusion Metrix:\n", metrics.confusion_matrix(y_test, knn_y_pred))

    print("---------------------------")

    svm = svm.SVC()
    svm.fit(X_train, y_train)
    svm_y_pred = svm.predict(X_test)
    print("SVM F1 score for each class: ", metrics.f1_score(y_test, svm_y_pred, average=None))
    print("SVM F1 score (macro): ", metrics.f1_score(y_test, svm_y_pred, average='weighted'))
    print()
    print("SVM Confusion Metrix:\n", metrics.confusion_matrix(y_test, svm_y_pred))

    nb = ComplementNB()
    nb.fit(X_train, y_train)
    nb_y_pred = nb.predict(X_test)
    print("NB F1 score for each class: ", metrics.f1_score(y_test, nb_y_pred, average=None))
    print("NB F1 score (macro): ", metrics.f1_score(y_test, nb_y_pred, average='weighted'))
    print()
    print("NB Confusion Metrix:\n", metrics.confusion_matrix(y_test, nb_y_pred))






