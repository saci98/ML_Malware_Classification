from pathlib import Path
import pandas as pd
from matplotlib import pyplot as plt
from scipy import sparse
import seaborn as sns

ftr_dir = Path("pre-extract")
data_dir = Path("data")


def show_1d_distribution(lbls: pd.DataFrame, X: pd.DataFrame, x: str, xlabel: str, title: str, figsize: tuple[int, int] = (8, 5)):
    plt.figure(figsize=figsize)
    X["Family"] = lbls["Class"]
    x_lim = (0, 10)
    ax = sns.boxplot(y='Family', x=x, data=X, orient="h", palette="Blues")
    ax.set(xlim=x_lim, xlabel=xlabel, title=title)
    plt.show()


def integrated_features(features: list[str], dataset: str) -> pd.DataFrame:
    def load_npz(file: str, prefix: str) -> pd.DataFrame:
        df = pd.DataFrame(sparse.load_npz(ftr_dir.joinpath(file)).toarray())
        df["ID"] = lbls.index
        df.set_index("ID", inplace=True)
        df.columns = [f"{prefix}--{str(col)}" for col in df.columns]
        return df
    if dataset == "andrea_microsoft":
        lbls = pd.read_csv(data_dir.joinpath("Andrea_Microsoft_dataset.csv"))
    else:
        lbls = pd.read_csv(data_dir.joinpath("trainLabels_"+dataset+".csv"))
    lbls.set_index("Id", inplace=True)
    dfs = []

    if dataset == "andrea_microsoft":
        if "API_check" in features:
            api_check_microsoft = load_npz("API_check_microsoft.npz", "api_check")
            dfs.append(api_check_microsoft)
    else:
        if "binary_size" in features:
            binary_size = load_npz("binary_size_"+dataset+".npz", "binary-size")
            # show_1d_distribution(lbls, binary_size, "binary-size--0", "Binary File Size",
                                 # title="Distribution of binary file size")
            dfs.append(binary_size)
        if "3_gram_bytes" in features:
            byte_grams = load_npz("3_gram_bytes_"+dataset+".npz", "byte")
            dfs.append(byte_grams)
        if "entropy" in features:
            entropy_benign = load_npz("entropy_"+dataset+".npz", "entropy")
            # show_1d_distribution(lbls, entropy_benign, "entropy--0", "Entropy File",
                                 # title="Distribution of entropy file")
            dfs.append(entropy_benign)

        if dataset == "malign":
            if "4_gram_API" in features:
                api_grams_malign = load_npz("4_gram_API_malign.npz", "api")
                dfs.append(api_grams_malign)
            if "4_gram_opcode" in features:
                opcode_grams_malign = load_npz("4_gram_opcode_malign.npz", "opcode")
                dfs.append(opcode_grams_malign)
            if "opcode_counter" in features:
                opcode_counter_malign = load_npz("opcode_counter_malign.npz", "opcode_count")
                dfs.append(opcode_counter_malign)
            if "API_check" in features:
                api_check_malign = load_npz("API_check_malign.npz", "api_check")
                dfs.append(api_check_malign)

    return pd.concat(dfs, axis="columns")

